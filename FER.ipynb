{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNvtn2th8W/lNhjOZaKlTL3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElhadjHoussem/Colab/blob/master/FER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_xSDw_fAQhd",
        "outputId": "4e897c2f-17d0-4a66-e096-7f13a409aeef"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph51o0u3BcCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb05bac-8edd-445d-99c3-466f8f45e7bc"
      },
      "source": [
        "model_folder = \"2\"\n",
        "model_name = \"/FacialExpressionRecognition\"\n",
        "colab_save_path =\"gdrive/MyDrive/GoogleColab/models/\" \n",
        "! mkdir gdrive/MyDrive/GoogleColab/models/2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘gdrive/MyDrive/GoogleColab/models/2’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0uAtDlnDbPP",
        "outputId": "ca5d1ff2-91bc-413d-f567-832ff8674557"
      },
      "source": [
        "!pwd\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwkHBFsVDfZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2bc50e5-42b3-445c-d606-1c60290b40dc"
      },
      "source": [
        "! mkdir ~/.kaggle "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvzS27fqDX4W"
      },
      "source": [
        "! cp /content/gdrive/MyDrive/GoogleColab/kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk27w9tlEXBl"
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOVExHQyEo9N",
        "outputId": "18b26791-6751-420a-9baf-fe25ad61ee7d"
      },
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kaggle\n",
            "  Using cached kaggle-1.5.12-py3-none-any.whl\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDW_YaazEdcW",
        "outputId": "cb71071a-0119-4e45-fdec-0f70bd95bca3"
      },
      "source": [
        "! kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                         title                                              size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "----------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "gpreda/reddit-vaccine-myths                                 Reddit Vaccine Myths                              235KB  2021-09-09 20:40:01          12011        991  1.0              \n",
            "crowww/a-large-scale-fish-dataset                           A Large Scale Fish Dataset                          3GB  2021-04-28 17:03:01           7320        553  0.9375           \n",
            "imsparsh/musicnet-dataset                                   MusicNet Dataset                                   22GB  2021-02-18 14:12:19           2922        217  1.0              \n",
            "dhruvildave/wikibooks-dataset                               Wikibooks Dataset                                   2GB  2021-07-03 18:37:20           2869        216  1.0              \n",
            "promptcloud/careerbuilder-job-listing-2020                  Careerbuilder Job Listing 2020                     42MB  2021-03-05 06:59:52           1870         72  1.0              \n",
            "nickuzmenkov/nih-chest-xrays-tfrecords                      NIH Chest X-rays TFRecords                         11GB  2021-03-09 04:49:23           1109         61  0.9411765        \n",
            "mathurinache/twitter-edge-nodes                             Twitter Edge Nodes                                342MB  2021-03-08 06:43:04            911         81  1.0              \n",
            "fatiimaezzahra/famous-iconic-women                          Famous Iconic Women                               838MB  2021-02-28 14:56:00           1342         99  0.75             \n",
            "simiotic/github-code-snippets                               GitHub Code Snippets                                7GB  2021-03-03 11:34:39            326         62  1.0              \n",
            "alsgroup/end-als                                            End ALS Kaggle Challenge                           12GB  2021-04-08 12:16:37            886        127  0.9375           \n",
            "coloradokb/dandelionimages                                  DandelionImages                                     4GB  2021-02-19 20:03:47            796         37  0.75             \n",
            "mathurinache/the-lj-speech-dataset                          The LJ Speech Dataset                               3GB  2021-02-15 09:19:54            335         42  1.0              \n",
            "landrykezebou/lvzhdr-tone-mapping-benchmark-dataset-tmonet  LVZ-HDR Tone Mapping Benchmark Dataset (TMO-Net)   24GB  2021-03-01 05:03:40            189         27  0.6875           \n",
            "imsparsh/accentdb-core-extended                             AccentDB - Core & Extended                          6GB  2021-02-17 14:22:54            139         28  0.875            \n",
            "stuartjames/lights                                          LightS: Light Specularity Dataset                  18GB  2021-02-18 14:32:26            139         26  0.6875           \n",
            "nickuzmenkov/ranzcr-clip-kfold-tfrecords                    RANZCR CLiP KFold TFRecords                         2GB  2021-02-21 13:29:51            128         20  0.875            \n",
            "datasnaek/youtube-new                                       Trending YouTube Video Statistics                 201MB  2019-06-03 00:56:47         149998       4149  0.7941176        \n",
            "zynicide/wine-reviews                                       Wine Reviews                                       51MB  2017-11-27 17:08:04         143473       3140  0.7941176        \n",
            "residentmario/ramen-ratings                                 Ramen Ratings                                      40KB  2018-01-11 16:04:39          26788        654  0.7058824        \n",
            "datasnaek/chess                                             Chess Game Dataset (Lichess)                        3MB  2017-09-04 03:09:09          21590        806  0.8235294        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwHbp9Vt0g4r",
        "outputId": "d8bc3456-4383-44d8-c37c-09eb6ccb5638"
      },
      "source": [
        "! kaggle datasets download -d ahmedmoorsy/facial-expression"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "facial-expression.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzSSCT6E2A63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20051596-620b-48e6-89e7-e10ce54ce6f6"
      },
      "source": [
        "! mkdir downloads"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘downloads’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP9LnY112LPt",
        "outputId": "56e76d25-2faf-4c33-98fb-b830879398df"
      },
      "source": [
        "! unzip facial-expression.zip -d downloads"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  facial-expression.zip\n",
            "replace downloads/fer2013.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace downloads/fer2013/fer2013.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0eRHh0O1e-d"
      },
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/downloads/fer2013.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZkA7Jj-dXRE",
        "outputId": "eff800a0-b3ee-440f-a65a-6f435df38be1"
      },
      "source": [
        "%tensorflow_version 1.10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.10`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYqlKwJ5V-OD",
        "outputId": "c4366cb7-a5ba-476d-de9a-4a294be326a9"
      },
      "source": [
        "pip install h5py==2.10.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires h5py~=3.1.0, but you have h5py 2.10.0 which is incompatible.\u001b[0m\n",
            "Successfully installed h5py-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-aWBHkIKsCv",
        "outputId": "5853fdfa-090e-480a-85cc-3a2ef16fec7e"
      },
      "source": [
        "!pip install keras2onnx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras2onnx\n",
            "  Downloading keras2onnx-1.7.0-py3-none-any.whl (96 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 20.7 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 20 kB 25.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 30 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 40 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 71 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 81 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 92 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 96 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting onnxconverter-common>=1.7.0\n",
            "  Downloading onnxconverter_common-1.8.1-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from keras2onnx) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras2onnx) (1.19.5)\n",
            "Collecting fire\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras2onnx) (2.23.0)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.10.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.3 MB 175 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire->keras2onnx) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire->keras2onnx) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx->keras2onnx) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras2onnx) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras2onnx) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras2onnx) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras2onnx) (1.24.3)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=ae028153f0d95b1638e6baa60c837b5c02358ed1bf7cb8a3edd097e41d39f588\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "Successfully built fire\n",
            "Installing collected packages: onnx, onnxconverter-common, fire, keras2onnx\n",
            "Successfully installed fire-0.4.0 keras2onnx-1.7.0 onnx-1.10.1 onnxconverter-common-1.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDkprZw6V68u",
        "outputId": "16a43d40-d0df-4aa3-da0b-73a01b1464f6"
      },
      "source": [
        "keras.__version__\n",
        "print(tf.__version__,keras.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.2 2.2.4-tf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd-Ll6rtza7R"
      },
      "source": [
        "import sys, os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils\n",
        "from keras.models import model_from_json\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Tesr_AE1pcz",
        "outputId": "0fe2a82c-f146-4759-e1dc-fac153141e09"
      },
      "source": [
        "print(\"start\")\n",
        "print(df.head())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start\n",
            "   emotion                                             pixels     Usage\n",
            "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
            "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
            "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
            "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
            "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBqQfR7aCc1g",
        "outputId": "e35fe0a0-c0c6-4c64-fb21-7841d062a923"
      },
      "source": [
        "row = df[\"pixels\"][0]\n",
        "\n",
        "pixels = np.array(row.split(\" \"),'float32')\n",
        "pixels.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2304,)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz79Lh6-H_dC",
        "outputId": "173f1537-b642-4f30-d75a-4ce09b58d8db"
      },
      "source": [
        "48*48"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2304"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBPmvvwr1woa"
      },
      "source": [
        "X_train,train_y,X_test,test_y=[],[],[],[]\n",
        "for index, row in df.iterrows():\n",
        "    val=row['pixels'].split(\" \")\n",
        "    try:\n",
        "        if 'Training' in row['Usage']:\n",
        "           X_train.append(np.array(val,'float32'))\n",
        "           train_y.append(row['emotion'])\n",
        "        elif 'PublicTest' in row['Usage']:\n",
        "           X_test.append(np.array(val,'float32'))\n",
        "           test_y.append(row['emotion'])\n",
        "    except:\n",
        "        print(f\"error occured at index :{index} and row:{row}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCKpDR_P2Ymp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f2217bf-c73d-4631-a091-2675571a0da7"
      },
      "source": [
        "num_labels = 7\n",
        "width, height = 48, 48\n",
        "\n",
        "\n",
        "X_train = np.array(X_train,'float32')\n",
        "train_y = np.array(train_y,'float32')\n",
        "X_test = np.array(X_test,'float32')\n",
        "test_y = np.array(test_y,'float32')\n",
        "\n",
        "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
        "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)\n",
        "\n",
        "\n",
        "#normalizing data between o and 1\n",
        "X_train -= np.mean(X_train, axis=0)\n",
        "X_train /= np.std(X_train, axis=0)\n",
        "\n",
        "X_test -= np.mean(X_test, axis=0)\n",
        "X_test /= np.std(X_test, axis=0)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], width, height, 1)\n",
        "\n",
        "X_test = X_test.reshape(X_test.shape[0], width, height, 1)\n",
        "\n",
        "print(f\"shape:{X_train.shape}\")\n",
        "print(f\"shape:{train_y.shape}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape:(28709, 48, 48, 1)\n",
            "shape:(28709, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX6LqatYyha-",
        "outputId": "82d387a9-79ce-4889-f3aa-9f3a39876bb6"
      },
      "source": [
        "\n",
        "\n",
        "##designing the cnn\n",
        "#1st convolution layer\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', input_shape=(X_train.shape[1:])))\n",
        "model.add(Conv2D(32,kernel_size= (5, 5), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "# model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#2nd convolution layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#3rd convolution layer\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#fully connected neural networks\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(num_labels, activation='softmax'))\n",
        "\n",
        "#Compliling the model\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "            optimizer=Adam(),\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 44, 44, 32)        832       \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 40, 40, 32)        25632     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 40, 40, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 40, 40, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 38, 38, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 36, 36, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 36, 36, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 18, 18, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 18, 18, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1024)              6423552   \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 7)                 7175      \n",
            "=================================================================\n",
            "Total params: 7,784,551\n",
            "Trainable params: 7,784,103\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euOt3ob99Bmu",
        "outputId": "5da33175-666e-4f5b-bf80-6683b86bd8d5"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 13826131673188989058\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 14215605667650958648\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 11643268194507421227\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 11338832282\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 9067640422104346159\n",
            "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF6WeFIoyw0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6dcebb-14da-45bf-b2ae-37d34b68eed7"
      },
      "source": [
        "epochs = 200\n",
        "batch_size = 64\n",
        "\n",
        "with(tf.device('GPU:0')):\n",
        "    #Training the model\n",
        "  model.fit(X_train, train_y,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(X_test, test_y), shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 28709 samples, validate on 3589 samples\n",
            "Epoch 1/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 1.9313 - accuracy: 0.3003 - val_loss: 1.6439 - val_accuracy: 0.3547\n",
            "Epoch 2/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 1.5324 - accuracy: 0.4008 - val_loss: 1.5206 - val_accuracy: 0.4118\n",
            "Epoch 3/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 1.4059 - accuracy: 0.4509 - val_loss: 1.3987 - val_accuracy: 0.4547\n",
            "Epoch 4/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 1.3023 - accuracy: 0.4985 - val_loss: 1.3108 - val_accuracy: 0.5007\n",
            "Epoch 5/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 1.2076 - accuracy: 0.5367 - val_loss: 1.3019 - val_accuracy: 0.5015\n",
            "Epoch 6/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 1.1144 - accuracy: 0.5727 - val_loss: 1.2497 - val_accuracy: 0.5272\n",
            "Epoch 7/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.9986 - accuracy: 0.6214 - val_loss: 1.2475 - val_accuracy: 0.5375\n",
            "Epoch 8/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.8799 - accuracy: 0.6686 - val_loss: 1.2510 - val_accuracy: 0.5525\n",
            "Epoch 9/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.7495 - accuracy: 0.7223 - val_loss: 1.2821 - val_accuracy: 0.5567\n",
            "Epoch 10/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.6146 - accuracy: 0.7743 - val_loss: 1.4008 - val_accuracy: 0.5662\n",
            "Epoch 11/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.4810 - accuracy: 0.8268 - val_loss: 1.6039 - val_accuracy: 0.5503\n",
            "Epoch 12/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.4011 - accuracy: 0.8583 - val_loss: 1.6765 - val_accuracy: 0.5589\n",
            "Epoch 13/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.3331 - accuracy: 0.8829 - val_loss: 1.6636 - val_accuracy: 0.5517\n",
            "Epoch 14/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.2949 - accuracy: 0.8998 - val_loss: 1.8588 - val_accuracy: 0.5595\n",
            "Epoch 15/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.2493 - accuracy: 0.9146 - val_loss: 1.7848 - val_accuracy: 0.5665\n",
            "Epoch 16/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.2201 - accuracy: 0.9269 - val_loss: 1.8620 - val_accuracy: 0.5659\n",
            "Epoch 17/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.1942 - accuracy: 0.9342 - val_loss: 1.9978 - val_accuracy: 0.5559\n",
            "Epoch 18/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.1849 - accuracy: 0.9389 - val_loss: 1.9559 - val_accuracy: 0.5603\n",
            "Epoch 19/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.1852 - accuracy: 0.9399 - val_loss: 2.1083 - val_accuracy: 0.5637\n",
            "Epoch 20/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.1682 - accuracy: 0.9449 - val_loss: 1.9966 - val_accuracy: 0.5598\n",
            "Epoch 21/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.1617 - accuracy: 0.9483 - val_loss: 2.1166 - val_accuracy: 0.5614\n",
            "Epoch 22/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.1536 - accuracy: 0.9498 - val_loss: 2.2295 - val_accuracy: 0.5720\n",
            "Epoch 23/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.1562 - accuracy: 0.9493 - val_loss: 2.1343 - val_accuracy: 0.5567\n",
            "Epoch 24/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.1413 - accuracy: 0.9548 - val_loss: 2.1431 - val_accuracy: 0.5729\n",
            "Epoch 25/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.1333 - accuracy: 0.9575 - val_loss: 2.2392 - val_accuracy: 0.5620\n",
            "Epoch 26/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.1312 - accuracy: 0.9581 - val_loss: 2.2789 - val_accuracy: 0.5564\n",
            "Epoch 27/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.1279 - accuracy: 0.9592 - val_loss: 2.4950 - val_accuracy: 0.5534\n",
            "Epoch 28/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.1131 - accuracy: 0.9646 - val_loss: 2.4564 - val_accuracy: 0.5539\n",
            "Epoch 29/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.1324 - accuracy: 0.9564 - val_loss: 2.3813 - val_accuracy: 0.5612\n",
            "Epoch 30/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.1206 - accuracy: 0.9611 - val_loss: 2.1468 - val_accuracy: 0.5561\n",
            "Epoch 31/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.1070 - accuracy: 0.9662 - val_loss: 2.4760 - val_accuracy: 0.5648\n",
            "Epoch 32/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.1126 - accuracy: 0.9640 - val_loss: 2.2641 - val_accuracy: 0.5626\n",
            "Epoch 33/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.1005 - accuracy: 0.9662 - val_loss: 2.5955 - val_accuracy: 0.5567\n",
            "Epoch 34/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.1105 - accuracy: 0.9656 - val_loss: 2.4690 - val_accuracy: 0.5656\n",
            "Epoch 35/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0971 - accuracy: 0.9689 - val_loss: 2.4482 - val_accuracy: 0.5692\n",
            "Epoch 36/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.1016 - accuracy: 0.9680 - val_loss: 2.5070 - val_accuracy: 0.5570\n",
            "Epoch 37/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.1016 - accuracy: 0.9684 - val_loss: 2.4172 - val_accuracy: 0.5539\n",
            "Epoch 38/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.1008 - accuracy: 0.9672 - val_loss: 2.6187 - val_accuracy: 0.5548\n",
            "Epoch 39/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0937 - accuracy: 0.9704 - val_loss: 2.5884 - val_accuracy: 0.5567\n",
            "Epoch 40/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0897 - accuracy: 0.9713 - val_loss: 2.6779 - val_accuracy: 0.5581\n",
            "Epoch 41/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0861 - accuracy: 0.9721 - val_loss: 2.4185 - val_accuracy: 0.5651\n",
            "Epoch 42/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0830 - accuracy: 0.9740 - val_loss: 2.3329 - val_accuracy: 0.5561\n",
            "Epoch 43/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0802 - accuracy: 0.9757 - val_loss: 2.6037 - val_accuracy: 0.5578\n",
            "Epoch 44/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0862 - accuracy: 0.9733 - val_loss: 2.5575 - val_accuracy: 0.5628\n",
            "Epoch 45/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0827 - accuracy: 0.9736 - val_loss: 2.6134 - val_accuracy: 0.5665\n",
            "Epoch 46/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0817 - accuracy: 0.9736 - val_loss: 2.5749 - val_accuracy: 0.5637\n",
            "Epoch 47/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0877 - accuracy: 0.9739 - val_loss: 2.7447 - val_accuracy: 0.5620\n",
            "Epoch 48/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0839 - accuracy: 0.9740 - val_loss: 2.4629 - val_accuracy: 0.5626\n",
            "Epoch 49/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0818 - accuracy: 0.9741 - val_loss: 2.6154 - val_accuracy: 0.5617\n",
            "Epoch 50/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0858 - accuracy: 0.9734 - val_loss: 2.6969 - val_accuracy: 0.5609\n",
            "Epoch 51/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0755 - accuracy: 0.9769 - val_loss: 3.0524 - val_accuracy: 0.5706\n",
            "Epoch 52/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.1014 - accuracy: 0.9705 - val_loss: 2.8931 - val_accuracy: 0.5648\n",
            "Epoch 53/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0845 - accuracy: 0.9742 - val_loss: 2.9167 - val_accuracy: 0.5578\n",
            "Epoch 54/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0801 - accuracy: 0.9761 - val_loss: 2.9986 - val_accuracy: 0.5648\n",
            "Epoch 55/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0729 - accuracy: 0.9776 - val_loss: 2.6735 - val_accuracy: 0.5444\n",
            "Epoch 56/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0685 - accuracy: 0.9800 - val_loss: 2.6408 - val_accuracy: 0.5609\n",
            "Epoch 57/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0650 - accuracy: 0.9799 - val_loss: 2.9331 - val_accuracy: 0.5653\n",
            "Epoch 58/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0733 - accuracy: 0.9778 - val_loss: 2.7111 - val_accuracy: 0.5651\n",
            "Epoch 59/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0687 - accuracy: 0.9786 - val_loss: 3.0943 - val_accuracy: 0.5653\n",
            "Epoch 60/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0705 - accuracy: 0.9788 - val_loss: 2.8497 - val_accuracy: 0.5525\n",
            "Epoch 61/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0634 - accuracy: 0.9791 - val_loss: 2.8222 - val_accuracy: 0.5603\n",
            "Epoch 62/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0576 - accuracy: 0.9825 - val_loss: 2.9629 - val_accuracy: 0.5581\n",
            "Epoch 63/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0569 - accuracy: 0.9820 - val_loss: 2.8084 - val_accuracy: 0.5553\n",
            "Epoch 64/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0642 - accuracy: 0.9801 - val_loss: 3.0803 - val_accuracy: 0.5587\n",
            "Epoch 65/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0585 - accuracy: 0.9812 - val_loss: 2.9966 - val_accuracy: 0.5534\n",
            "Epoch 66/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0627 - accuracy: 0.9805 - val_loss: 2.8658 - val_accuracy: 0.5522\n",
            "Epoch 67/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0541 - accuracy: 0.9831 - val_loss: 3.0174 - val_accuracy: 0.5662\n",
            "Epoch 68/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0552 - accuracy: 0.9829 - val_loss: 2.9678 - val_accuracy: 0.5525\n",
            "Epoch 69/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0654 - accuracy: 0.9801 - val_loss: 2.7391 - val_accuracy: 0.5595\n",
            "Epoch 70/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0559 - accuracy: 0.9823 - val_loss: 2.9316 - val_accuracy: 0.5550\n",
            "Epoch 71/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0519 - accuracy: 0.9843 - val_loss: 2.9185 - val_accuracy: 0.5606\n",
            "Epoch 72/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0548 - accuracy: 0.9831 - val_loss: 2.8008 - val_accuracy: 0.5573\n",
            "Epoch 73/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0887 - accuracy: 0.9740 - val_loss: 2.8949 - val_accuracy: 0.5492\n",
            "Epoch 74/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0653 - accuracy: 0.9805 - val_loss: 3.1059 - val_accuracy: 0.5584\n",
            "Epoch 75/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0664 - accuracy: 0.9803 - val_loss: 2.8261 - val_accuracy: 0.5475\n",
            "Epoch 76/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0627 - accuracy: 0.9811 - val_loss: 2.8526 - val_accuracy: 0.5589\n",
            "Epoch 77/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0896 - accuracy: 0.9746 - val_loss: 2.8683 - val_accuracy: 0.5503\n",
            "Epoch 78/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0669 - accuracy: 0.9789 - val_loss: 3.2924 - val_accuracy: 0.5553\n",
            "Epoch 79/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0656 - accuracy: 0.9807 - val_loss: 3.3791 - val_accuracy: 0.5626\n",
            "Epoch 80/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0624 - accuracy: 0.9810 - val_loss: 3.4031 - val_accuracy: 0.5653\n",
            "Epoch 81/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0560 - accuracy: 0.9830 - val_loss: 3.0273 - val_accuracy: 0.5712\n",
            "Epoch 82/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0646 - accuracy: 0.9814 - val_loss: 2.9734 - val_accuracy: 0.5651\n",
            "Epoch 83/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0527 - accuracy: 0.9844 - val_loss: 3.0832 - val_accuracy: 0.5642\n",
            "Epoch 84/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0621 - accuracy: 0.9828 - val_loss: 2.6227 - val_accuracy: 0.5626\n",
            "Epoch 85/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0513 - accuracy: 0.9840 - val_loss: 2.8268 - val_accuracy: 0.5614\n",
            "Epoch 86/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0506 - accuracy: 0.9850 - val_loss: 3.7151 - val_accuracy: 0.5678\n",
            "Epoch 87/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0459 - accuracy: 0.9850 - val_loss: 3.1534 - val_accuracy: 0.5536\n",
            "Epoch 88/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0816 - accuracy: 0.9779 - val_loss: 4.9028 - val_accuracy: 0.4712\n",
            "Epoch 89/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0711 - accuracy: 0.9790 - val_loss: 3.2578 - val_accuracy: 0.5623\n",
            "Epoch 90/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0601 - accuracy: 0.9821 - val_loss: 3.5036 - val_accuracy: 0.5545\n",
            "Epoch 91/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0503 - accuracy: 0.9837 - val_loss: 3.9668 - val_accuracy: 0.5609\n",
            "Epoch 92/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0589 - accuracy: 0.9819 - val_loss: 3.4369 - val_accuracy: 0.5581\n",
            "Epoch 93/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0542 - accuracy: 0.9843 - val_loss: 3.4274 - val_accuracy: 0.5656\n",
            "Epoch 94/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0460 - accuracy: 0.9861 - val_loss: 2.7516 - val_accuracy: 0.5609\n",
            "Epoch 95/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0498 - accuracy: 0.9852 - val_loss: 3.2606 - val_accuracy: 0.5687\n",
            "Epoch 96/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0552 - accuracy: 0.9840 - val_loss: 3.6179 - val_accuracy: 0.5548\n",
            "Epoch 97/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0501 - accuracy: 0.9848 - val_loss: 3.5909 - val_accuracy: 0.5631\n",
            "Epoch 98/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0489 - accuracy: 0.9858 - val_loss: 2.7147 - val_accuracy: 0.5589\n",
            "Epoch 99/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0500 - accuracy: 0.9852 - val_loss: 3.6968 - val_accuracy: 0.5681\n",
            "Epoch 100/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0502 - accuracy: 0.9846 - val_loss: 3.4493 - val_accuracy: 0.5545\n",
            "Epoch 101/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0427 - accuracy: 0.9871 - val_loss: 3.7611 - val_accuracy: 0.5548\n",
            "Epoch 102/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0420 - accuracy: 0.9881 - val_loss: 3.2820 - val_accuracy: 0.5609\n",
            "Epoch 103/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0485 - accuracy: 0.9851 - val_loss: 3.4827 - val_accuracy: 0.5606\n",
            "Epoch 104/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0543 - accuracy: 0.9837 - val_loss: 2.7555 - val_accuracy: 0.5508\n",
            "Epoch 105/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0442 - accuracy: 0.9871 - val_loss: 3.2232 - val_accuracy: 0.5681\n",
            "Epoch 106/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0420 - accuracy: 0.9875 - val_loss: 3.1266 - val_accuracy: 0.5648\n",
            "Epoch 107/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0469 - accuracy: 0.9861 - val_loss: 3.6638 - val_accuracy: 0.5676\n",
            "Epoch 108/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0498 - accuracy: 0.9860 - val_loss: 3.3977 - val_accuracy: 0.5709\n",
            "Epoch 109/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0461 - accuracy: 0.9868 - val_loss: 2.9787 - val_accuracy: 0.5631\n",
            "Epoch 110/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0415 - accuracy: 0.9864 - val_loss: 3.4729 - val_accuracy: 0.5603\n",
            "Epoch 111/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0433 - accuracy: 0.9876 - val_loss: 3.0753 - val_accuracy: 0.5690\n",
            "Epoch 112/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0473 - accuracy: 0.9858 - val_loss: 3.1460 - val_accuracy: 0.5687\n",
            "Epoch 113/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0404 - accuracy: 0.9885 - val_loss: 3.4853 - val_accuracy: 0.5715\n",
            "Epoch 114/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0432 - accuracy: 0.9872 - val_loss: 3.1778 - val_accuracy: 0.5653\n",
            "Epoch 115/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0418 - accuracy: 0.9872 - val_loss: 3.9179 - val_accuracy: 0.5673\n",
            "Epoch 116/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0511 - accuracy: 0.9853 - val_loss: 2.7898 - val_accuracy: 0.5567\n",
            "Epoch 117/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0479 - accuracy: 0.9858 - val_loss: 3.2240 - val_accuracy: 0.5723\n",
            "Epoch 118/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0404 - accuracy: 0.9881 - val_loss: 3.4266 - val_accuracy: 0.5556\n",
            "Epoch 119/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0367 - accuracy: 0.9889 - val_loss: 3.1802 - val_accuracy: 0.5600\n",
            "Epoch 120/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0370 - accuracy: 0.9887 - val_loss: 3.2404 - val_accuracy: 0.5637\n",
            "Epoch 121/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0414 - accuracy: 0.9884 - val_loss: 2.8082 - val_accuracy: 0.5617\n",
            "Epoch 122/200\n",
            "28709/28709 [==============================] - 34s 1ms/step - loss: 0.0380 - accuracy: 0.9882 - val_loss: 3.4051 - val_accuracy: 0.5665\n",
            "Epoch 123/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0408 - accuracy: 0.9875 - val_loss: 3.5917 - val_accuracy: 0.5637\n",
            "Epoch 124/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0453 - accuracy: 0.9865 - val_loss: 3.4668 - val_accuracy: 0.5634\n",
            "Epoch 125/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0384 - accuracy: 0.9876 - val_loss: 3.6843 - val_accuracy: 0.5564\n",
            "Epoch 126/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0404 - accuracy: 0.9883 - val_loss: 4.5346 - val_accuracy: 0.5623\n",
            "Epoch 127/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0353 - accuracy: 0.9894 - val_loss: 3.0681 - val_accuracy: 0.5606\n",
            "Epoch 128/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0365 - accuracy: 0.9891 - val_loss: 4.2967 - val_accuracy: 0.5517\n",
            "Epoch 129/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0420 - accuracy: 0.9877 - val_loss: 3.8702 - val_accuracy: 0.5623\n",
            "Epoch 130/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0425 - accuracy: 0.9889 - val_loss: 3.2590 - val_accuracy: 0.5567\n",
            "Epoch 131/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0433 - accuracy: 0.9876 - val_loss: 3.1308 - val_accuracy: 0.5567\n",
            "Epoch 132/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0353 - accuracy: 0.9892 - val_loss: 3.4380 - val_accuracy: 0.5534\n",
            "Epoch 133/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0364 - accuracy: 0.9895 - val_loss: 3.5283 - val_accuracy: 0.5575\n",
            "Epoch 134/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0387 - accuracy: 0.9887 - val_loss: 3.7874 - val_accuracy: 0.5506\n",
            "Epoch 135/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0434 - accuracy: 0.9879 - val_loss: 3.5230 - val_accuracy: 0.5561\n",
            "Epoch 136/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0440 - accuracy: 0.9873 - val_loss: 3.4800 - val_accuracy: 0.5584\n",
            "Epoch 137/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0364 - accuracy: 0.9892 - val_loss: 3.0935 - val_accuracy: 0.5575\n",
            "Epoch 138/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0369 - accuracy: 0.9895 - val_loss: 3.1935 - val_accuracy: 0.5522\n",
            "Epoch 139/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0376 - accuracy: 0.9884 - val_loss: 4.4146 - val_accuracy: 0.5508\n",
            "Epoch 140/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0388 - accuracy: 0.9886 - val_loss: 3.6239 - val_accuracy: 0.5617\n",
            "Epoch 141/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0357 - accuracy: 0.9894 - val_loss: 3.5195 - val_accuracy: 0.5542\n",
            "Epoch 142/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0374 - accuracy: 0.9890 - val_loss: 3.8671 - val_accuracy: 0.5508\n",
            "Epoch 143/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0312 - accuracy: 0.9906 - val_loss: 3.5639 - val_accuracy: 0.5492\n",
            "Epoch 144/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0376 - accuracy: 0.9885 - val_loss: 3.9309 - val_accuracy: 0.5536\n",
            "Epoch 145/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0401 - accuracy: 0.9882 - val_loss: 4.1862 - val_accuracy: 0.5587\n",
            "Epoch 146/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0384 - accuracy: 0.9889 - val_loss: 4.7884 - val_accuracy: 0.5578\n",
            "Epoch 147/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0356 - accuracy: 0.9885 - val_loss: 4.2840 - val_accuracy: 0.5559\n",
            "Epoch 148/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0359 - accuracy: 0.9894 - val_loss: 3.7542 - val_accuracy: 0.5595\n",
            "Epoch 149/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0407 - accuracy: 0.9884 - val_loss: 3.5273 - val_accuracy: 0.5614\n",
            "Epoch 150/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0345 - accuracy: 0.9893 - val_loss: 2.5670 - val_accuracy: 0.5623\n",
            "Epoch 151/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0341 - accuracy: 0.9904 - val_loss: 3.7826 - val_accuracy: 0.5489\n",
            "Epoch 152/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0353 - accuracy: 0.9891 - val_loss: 3.3001 - val_accuracy: 0.5603\n",
            "Epoch 153/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0416 - accuracy: 0.9884 - val_loss: 4.4156 - val_accuracy: 0.5581\n",
            "Epoch 154/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0324 - accuracy: 0.9904 - val_loss: 4.5045 - val_accuracy: 0.5584\n",
            "Epoch 155/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0349 - accuracy: 0.9894 - val_loss: 4.3933 - val_accuracy: 0.5581\n",
            "Epoch 156/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0413 - accuracy: 0.9876 - val_loss: 5.5793 - val_accuracy: 0.5548\n",
            "Epoch 157/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0399 - accuracy: 0.9890 - val_loss: 3.7657 - val_accuracy: 0.5637\n",
            "Epoch 158/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0388 - accuracy: 0.9885 - val_loss: 3.2996 - val_accuracy: 0.5692\n",
            "Epoch 159/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0369 - accuracy: 0.9896 - val_loss: 4.4232 - val_accuracy: 0.5506\n",
            "Epoch 160/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0367 - accuracy: 0.9898 - val_loss: 4.1463 - val_accuracy: 0.5595\n",
            "Epoch 161/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0353 - accuracy: 0.9892 - val_loss: 3.4285 - val_accuracy: 0.5578\n",
            "Epoch 162/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0370 - accuracy: 0.9886 - val_loss: 3.9586 - val_accuracy: 0.5548\n",
            "Epoch 163/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0362 - accuracy: 0.9903 - val_loss: 4.4360 - val_accuracy: 0.5612\n",
            "Epoch 164/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0328 - accuracy: 0.9906 - val_loss: 3.4567 - val_accuracy: 0.5623\n",
            "Epoch 165/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0349 - accuracy: 0.9892 - val_loss: 3.0733 - val_accuracy: 0.5581\n",
            "Epoch 166/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0357 - accuracy: 0.9891 - val_loss: 4.0775 - val_accuracy: 0.5545\n",
            "Epoch 167/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0393 - accuracy: 0.9890 - val_loss: 4.5541 - val_accuracy: 0.5606\n",
            "Epoch 168/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0363 - accuracy: 0.9902 - val_loss: 3.6981 - val_accuracy: 0.5598\n",
            "Epoch 169/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0343 - accuracy: 0.9897 - val_loss: 3.5457 - val_accuracy: 0.5612\n",
            "Epoch 170/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0392 - accuracy: 0.9896 - val_loss: 3.8819 - val_accuracy: 0.5536\n",
            "Epoch 171/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0364 - accuracy: 0.9889 - val_loss: 3.2569 - val_accuracy: 0.5539\n",
            "Epoch 172/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0353 - accuracy: 0.9890 - val_loss: 5.9372 - val_accuracy: 0.5606\n",
            "Epoch 173/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0354 - accuracy: 0.9897 - val_loss: 6.3898 - val_accuracy: 0.5578\n",
            "Epoch 174/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0371 - accuracy: 0.9890 - val_loss: 4.1709 - val_accuracy: 0.5626\n",
            "Epoch 175/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0324 - accuracy: 0.9907 - val_loss: 5.2497 - val_accuracy: 0.5637\n",
            "Epoch 176/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0391 - accuracy: 0.9889 - val_loss: 3.7876 - val_accuracy: 0.5609\n",
            "Epoch 177/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0353 - accuracy: 0.9897 - val_loss: 3.9378 - val_accuracy: 0.5506\n",
            "Epoch 178/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0425 - accuracy: 0.9885 - val_loss: 4.9482 - val_accuracy: 0.5642\n",
            "Epoch 179/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0334 - accuracy: 0.9898 - val_loss: 3.5538 - val_accuracy: 0.5645\n",
            "Epoch 180/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0306 - accuracy: 0.9912 - val_loss: 3.4425 - val_accuracy: 0.5617\n",
            "Epoch 181/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0402 - accuracy: 0.9890 - val_loss: 4.0889 - val_accuracy: 0.5548\n",
            "Epoch 182/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0421 - accuracy: 0.9873 - val_loss: 3.6731 - val_accuracy: 0.5631\n",
            "Epoch 183/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0350 - accuracy: 0.9897 - val_loss: 3.5492 - val_accuracy: 0.5587\n",
            "Epoch 184/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0337 - accuracy: 0.9903 - val_loss: 4.2605 - val_accuracy: 0.5645\n",
            "Epoch 185/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0332 - accuracy: 0.9913 - val_loss: 3.6065 - val_accuracy: 0.5620\n",
            "Epoch 186/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0330 - accuracy: 0.9906 - val_loss: 3.1830 - val_accuracy: 0.5483\n",
            "Epoch 187/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0329 - accuracy: 0.9896 - val_loss: 5.2338 - val_accuracy: 0.5545\n",
            "Epoch 188/200\n",
            "28709/28709 [==============================] - 36s 1ms/step - loss: 0.0385 - accuracy: 0.9891 - val_loss: 3.4823 - val_accuracy: 0.5556\n",
            "Epoch 189/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0383 - accuracy: 0.9896 - val_loss: 3.8260 - val_accuracy: 0.5528\n",
            "Epoch 190/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0349 - accuracy: 0.9893 - val_loss: 4.9402 - val_accuracy: 0.5617\n",
            "Epoch 191/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0337 - accuracy: 0.9908 - val_loss: 4.5275 - val_accuracy: 0.5508\n",
            "Epoch 192/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0361 - accuracy: 0.9899 - val_loss: 4.0606 - val_accuracy: 0.5645\n",
            "Epoch 193/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0348 - accuracy: 0.9900 - val_loss: 3.5807 - val_accuracy: 0.5687\n",
            "Epoch 194/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0275 - accuracy: 0.9908 - val_loss: 4.0184 - val_accuracy: 0.5667\n",
            "Epoch 195/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0339 - accuracy: 0.9900 - val_loss: 3.4725 - val_accuracy: 0.5545\n",
            "Epoch 196/200\n",
            "28709/28709 [==============================] - 36s 1ms/step - loss: 0.0358 - accuracy: 0.9893 - val_loss: 5.2694 - val_accuracy: 0.5581\n",
            "Epoch 197/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0294 - accuracy: 0.9915 - val_loss: 4.4878 - val_accuracy: 0.5595\n",
            "Epoch 198/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0287 - accuracy: 0.9910 - val_loss: 4.1090 - val_accuracy: 0.5623\n",
            "Epoch 199/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0292 - accuracy: 0.9914 - val_loss: 3.8065 - val_accuracy: 0.5651\n",
            "Epoch 200/200\n",
            "28709/28709 [==============================] - 35s 1ms/step - loss: 0.0353 - accuracy: 0.9904 - val_loss: 3.9168 - val_accuracy: 0.5670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuTIjS43IQuM"
      },
      "source": [
        "model_save_path = colab_save_path + model_folder + model_name \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw0nYSbuylxL",
        "outputId": "5a29dd90-0795-493f-c35a-2dbbf8974a6a"
      },
      "source": [
        "# serialize model to JSON\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(model_save_path+\".json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(model_save_path+\".h5\")\n",
        "print(\"Saved model to disk in =>\" + model_save_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk in =>gdrive/MyDrive/GoogleColab/models/2/FacialExpressionRecognition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omfKp94WJAWh"
      },
      "source": [
        "**Convert keras Model to Onnx**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sWsav7hzSnFQ",
        "outputId": "f95e6d43-7c3a-46fe-dc43-cd5f18ab9114"
      },
      "source": [
        "model_save_path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'gdrive/MyDrive/GoogleColab/models/2/FacialExpressionRecognition'"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0kibejvIrgn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31b63dab-69dd-4ffe-c71b-9afced90a269"
      },
      "source": [
        "import onnx\n",
        "import os\n",
        "import keras2onnx\n",
        "from keras.models import model_from_json\n",
        "\n",
        "os.environ['TF_KERAS'] = '1'\n",
        "\n",
        "onnx_model_name = model_name+'.onnx'\n",
        "model = model_from_json(open(model_save_path+\".json\", \"r\").read())\n",
        "\n",
        "#load weights\n",
        "h5_model=model_save_path+\".h5\"\n",
        "model.load_weights(h5_model)\n",
        "onnx_model = keras2onnx.convert_keras(model, model.name,target_opset=9)\n",
        "onnx.save_model(onnx_model, model_save_path+'.onnx')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The ONNX operator number change on the optimization: 59 -> 29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPjnaB8fBAPY"
      },
      "source": [
        ""
      ]
    }
  ]
}